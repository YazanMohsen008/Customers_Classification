{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tabulate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-906cb75678fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtabulate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'"
     ]
    }
   ],
   "source": [
    "import tabulate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('customers.csv')\n",
    "Features = dataset.iloc[:, :-1].values\n",
    "Segmentations = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imputer.fit(Features[:, 1:8])\n",
    "Features[:, 1:8] = imputer.transform(Features[:, 1:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable (Gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelEncoder = LabelEncoder()\n",
    "Features[:,0]= labelEncoder.fit_transform(Features[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable (Ever_Married)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelEncoder = LabelEncoder()\n",
    "Features[:,1]= labelEncoder.fit_transform(Features[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable (Graduated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "Features[:,3]= labelEncoder.fit_transform(Features[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable(Spending_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "Features[:,6]= labelEncoder.fit_transform(Features[:,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable(Segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "Segmentations= labelEncoder.fit_transform(Segmentations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Independent Variable (Profession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "columnTransformer = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [4])], remainder='passthrough')\n",
    "Features = np.array(columnTransformer.fit_transform(Features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Features_train, Features_test, Segmentations_train, Segmentations_test = train_test_split(Features, Segmentations, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling (Age,Work_Experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "Features_train[:, 11:12] = sc.fit_transform(Features_train[:, 11:12])\n",
    "Features_test[:, 11:12] = sc.fit_transform(Features_test[:, 11:12])\n",
    "\n",
    "Features_train[:, 14:15] = sc.fit_transform(Features_train[:, 14:15])\n",
    "Features_test[:, 14:15] = sc.fit_transform(Features_test[:, 14:15])\n",
    "\n",
    "Features_train[:, 15:16] = sc.fit_transform(Features_train[:, 15:16])\n",
    "Features_test[:, 15:16] = sc.fit_transform(Features_test[:, 15:16])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Decision Tree Classification model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16091961 0.         0.         0.         0.         0.05077387\n",
      " 0.         0.         0.02047727 0.         0.         0.52832917\n",
      " 0.02666054 0.00112168 0.16841958 0.04329827]\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decisionTreeClassifier = DecisionTreeClassifier( random_state = 2,max_depth=5)\n",
    "decisionTreeClassifier.fit(Features_train, Segmentations_train)\n",
    "importance = decisionTreeClassifier.feature_importances_\n",
    "max=-1\n",
    "maxIndex=-1\n",
    "print(importance)\n",
    "for i,v in enumerate(importance):\n",
    "    if(max<v):\n",
    "        max=v\n",
    "        maxIndex=i\n",
    "print(maxIndex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Segmentations_pred_train = decisionTreeClassifier.predict(Features_train)\n",
    "Segmentations_pred_test = decisionTreeClassifier.predict(Features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Score for Decision Tree Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5277138303523995"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Segmentations_train,Segmentations_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features train classification data report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features train classification data report\n",
      "\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n",
      "|           |       0 |       1 |       2 |       3 |   accuracy |   macro avg |   weighted avg |\n",
      "+===========+=========+=========+=========+=========+============+=============+================+\n",
      "| precision |    0.43 |    0.44 |    0.55 |    0.66 |       0.53 |        0.52 |           0.53 |\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n",
      "| recall    |    0.51 |    0.37 |    0.48 |    0.72 |       0.53 |        0.52 |           0.53 |\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n",
      "| f1-score  |    0.47 |    0.40 |    0.52 |    0.69 |       0.53 |        0.52 |           0.52 |\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n",
      "| support   | 1378.00 | 1314.00 | 1363.00 | 1592.00 |       0.53 |     5647.00 |        5647.00 |\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"features train classification data report\\n\")\n",
    "r1 = pd.DataFrame(classification_report(Segmentations_train,Segmentations_pred_train, output_dict=True))\n",
    "print(r1.to_markdown(tablefmt='grid', floatfmt='.2f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Score for Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5196199917389508"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Segmentations_test,Segmentations_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features test classification data report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features test classification data report\n",
      "\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n",
      "|           |      0 |      1 |      2 |      3 |   accuracy |   macro avg |   weighted avg |\n",
      "+===========+========+========+========+========+============+=============+================+\n",
      "| precision |   0.45 |   0.37 |   0.58 |   0.64 |       0.52 |        0.51 |           0.52 |\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n",
      "| recall    |   0.53 |   0.32 |   0.49 |   0.70 |       0.52 |        0.51 |           0.52 |\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n",
      "| f1-score  |   0.49 |   0.34 |   0.53 |   0.67 |       0.52 |        0.51 |           0.52 |\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n",
      "| support   | 594.00 | 544.00 | 607.00 | 676.00 |       0.52 |     2421.00 |        2421.00 |\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"features test classification data report\\n\")\n",
    "r1 = pd.DataFrame(classification_report(Segmentations_test,Segmentations_pred_test, output_dict=True))\n",
    "print(r1.to_markdown(tablefmt='grid', floatfmt='.2f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Random Forest Classification model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomForestClassifier = RandomForestClassifier(random_state=5,max_depth=7,n_estimators=9)\n",
    "randomForestClassifier.fit(Features_train, Segmentations_train)\n",
    "importance = randomForestClassifier.feature_importances_\n",
    "max=-1\n",
    "maxIndex=-1\n",
    "for i,v in enumerate(importance):\n",
    "    if(max<v):\n",
    "        max=v\n",
    "        maxIndex=i\n",
    "print(maxIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Decision Tree Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Segmentations_pred_train = randomForestClassifier.predict(Features_train)\n",
    "Segmentations_pred_test = randomForestClassifier.predict(Features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Segmentations_test, Segmentations_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Score for Random Forest Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5693288471754914"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Segmentations_train,Segmentations_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features train classification data report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features train classification data report\n",
      "\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n",
      "|           |       0 |       1 |       2 |       3 |   accuracy |   macro avg |   weighted avg |\n",
      "+===========+=========+=========+=========+=========+============+=============+================+\n",
      "| precision |    0.50 |    0.49 |    0.57 |    0.67 |       0.57 |        0.56 |           0.56 |\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n",
      "| recall    |    0.52 |    0.39 |    0.59 |    0.74 |       0.57 |        0.56 |           0.57 |\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n",
      "| f1-score  |    0.51 |    0.44 |    0.58 |    0.71 |       0.57 |        0.56 |           0.56 |\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n",
      "| support   | 1378.00 | 1314.00 | 1363.00 | 1592.00 |       0.57 |     5647.00 |        5647.00 |\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"features train classification data report\\n\")\n",
    "r1 = pd.DataFrame(classification_report(Segmentations_train,Segmentations_pred_train, output_dict=True))\n",
    "print(r1.to_markdown(tablefmt='grid', floatfmt='.2f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Score for Random Forest Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5353159851301115"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Segmentations_test,Segmentations_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features test calssification data report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features test classification data report\n",
      "\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n",
      "|           |      0 |      1 |      2 |      3 |   accuracy |   macro avg |   weighted avg |\n",
      "+===========+========+========+========+========+============+=============+================+\n",
      "| precision |   0.46 |   0.41 |   0.58 |   0.64 |       0.54 |        0.52 |           0.53 |\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n",
      "| recall    |   0.49 |   0.31 |   0.60 |   0.69 |       0.54 |        0.52 |           0.54 |\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n",
      "| f1-score  |   0.47 |   0.35 |   0.59 |   0.66 |       0.54 |        0.52 |           0.53 |\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n",
      "| support   | 594.00 | 544.00 | 607.00 | 676.00 |       0.54 |     2421.00 |        2421.00 |\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"features test classification data report\\n\")\n",
    "r1 = pd.DataFrame(classification_report(Segmentations_test,Segmentations_pred_test, output_dict=True))\n",
    "print(r1.to_markdown(tablefmt='grid', floatfmt='.2f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the new customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('new_customers.csv')\n",
    "newFeatures = dataset.iloc[:, :].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imputer.fit(Features[:, 1:8])\n",
    "newFeatures[:, 1:8] = imputer.transform(newFeatures[:, 1:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable (Gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "newFeatures[:,0]= labelEncoder.fit_transform(newFeatures[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable (Ever_Married)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "newFeatures[:,1]= labelEncoder.fit_transform(newFeatures[:,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable (Graduated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "newFeatures[:,3]= labelEncoder.fit_transform(newFeatures[:,3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable(Spending_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "newFeatures[:,6]= labelEncoder.fit_transform(newFeatures[:,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Independent Variable (Profession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnTransformer = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [4])], remainder='passthrough')\n",
    "newFeatures = np.array(columnTransformer.fit_transform(newFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the newCustomer set results Using Decision Tree Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 150, 'B': 51, 'C': 33, 'D': 48}\n"
     ]
    }
   ],
   "source": [
    "newSegmentations_pred = decisionTreeClassifier.predict(newFeatures)\n",
    "\n",
    "data_distributed = {'A':0,'B':0,'C':0,'D':0} \n",
    "for i in newSegmentations_pred: \n",
    "    if(i==0): \n",
    "        data_distributed['A'] +=1 \n",
    "    if(i==1): \n",
    "        data_distributed['B'] +=1  \n",
    "    if(i==2): \n",
    "        data_distributed['C'] +=1  \n",
    "    if(i==3): \n",
    "        data_distributed['D'] +=1  \n",
    "data_distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the newCustomer set results Using Random Forest classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 54, 'B': 43, 'C': 80, 'D': 105}\n"
     ]
    }
   ],
   "source": [
    "newSegmentations_pred = randomForestClassifier.predict(newFeatures)\n",
    "data_distributed = {'A':0,'B':0,'C':0,'D':0} \n",
    "for i in newSegmentations_pred: \n",
    "    x=x+1 \n",
    "    if(i==0): \n",
    "        data_distributed['A'] +=1 \n",
    "    if(i==1): \n",
    "        data_distributed['B'] +=1  \n",
    "    if(i==2): \n",
    "        data_distributed['C'] +=1  \n",
    "    if(i==3): \n",
    "        data_distributed['D'] +=1  \n",
    "print(data_distributed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b6079af21e979945c8c029267b6c1970daa06c7ff8dc867c0071b7e9ea55e6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
