{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('customers.csv')\n",
    "Features = dataset.iloc[:, :-1].values\n",
    "Segmentations = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# nan for string variables\n",
    "nan_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "Features[:, 0:2] = nan_imputer.fit_transform(Features[:, 0:2])\n",
    "Features[:, 3:5] = nan_imputer.fit_transform(Features[:, 3:5])\n",
    "Features[:, 6:7] = nan_imputer.fit_transform(Features[:, 6:7])\n",
    "\n",
    "# nan for a numerical variables\n",
    "nan_num_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "Features[:, 2:3] = nan_num_imputer.fit_transform(Features[:, 2:3])\n",
    "Features[:, 5:6] = nan_num_imputer.fit_transform(Features[:, 5:6])\n",
    "Features[:, 7:8] = nan_num_imputer.fit_transform(Features[:, 7:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable (Gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelEncoder = LabelEncoder()\n",
    "Features[:,0]= labelEncoder.fit_transform(Features[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable (Ever_Married)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelEncoder = LabelEncoder()\n",
    "Features[:,1]= labelEncoder.fit_transform(Features[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable (Graduated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "Features[:,3]= labelEncoder.fit_transform(Features[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable(Spending_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spending_Score_Map = {'Low': 0, 'Average': 1, 'High': 2}\n",
    "for observation in Features:\n",
    "    observation[6] = Spending_Score_Map[observation[6]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable(Segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0 'A' 'B' ... 'D' 'B' 'B']\n"
     ]
    }
   ],
   "source": [
    "# labelEncoder = LabelEncoder()\n",
    "# Segmentations= labelEncoder.fit_transform(Segmentations)\n",
    "\n",
    "a=[Segmentations]\n",
    "print(xa[0])\n",
    "columnTransformer = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "xa = np.array(columnTransformer.fit_transform(a))\n",
    "print(xa[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Independent Variable (Profession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "columnTransformer = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [4])], remainder='passthrough')\n",
    "Features = np.array(columnTransformer.fit_transform(Features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling (Age,Work_Experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "Features[:, 11:12] = sc.fit_transform(Features[:, 11:12])\n",
    "Features[:, 14:15] = sc.fit_transform(Features[:, 14:15])\n",
    "Features[:, 15:16] = sc.fit_transform(Features[:, 15:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Features_train, Features_test, Segmentations_train, Segmentations_test = train_test_split(Features, Segmentations, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Decision Tree Classification model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16070249 0.         0.         0.         0.         0.05078912\n",
      " 0.         0.         0.02044964 0.         0.         0.52876895\n",
      " 0.02662457 0.00072039 0.16821208 0.04373276]\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decisionTreeClassifier = DecisionTreeClassifier( random_state = 2,max_depth=5)\n",
    "decisionTreeClassifier.fit(Features_train, Segmentations_train)\n",
    "importance = decisionTreeClassifier.feature_importances_\n",
    "max=-1\n",
    "maxIndex=-1\n",
    "print(importance)\n",
    "for i,v in enumerate(importance):\n",
    "    if(max<v):\n",
    "        max=v\n",
    "        maxIndex=i\n",
    "print(maxIndex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Segmentations_pred_train = decisionTreeClassifier.predict(Features_train)\n",
    "Segmentations_pred_test = decisionTreeClassifier.predict(Features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Score for Decision Tree Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5280680007083407"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Segmentations_train,Segmentations_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features train classification data report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features train classification data report\n",
      "\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n",
      "|           |       A |       B |       C |       D |   accuracy |   macro avg |   weighted avg |\n",
      "+===========+=========+=========+=========+=========+============+=============+================+\n",
      "| precision |    0.43 |    0.44 |    0.56 |    0.66 |       0.53 |        0.52 |           0.53 |\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n",
      "| recall    |    0.51 |    0.37 |    0.48 |    0.71 |       0.53 |        0.52 |           0.53 |\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n",
      "| f1-score  |    0.47 |    0.40 |    0.52 |    0.69 |       0.53 |        0.52 |           0.53 |\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n",
      "| support   | 1378.00 | 1314.00 | 1363.00 | 1592.00 |       0.53 |     5647.00 |        5647.00 |\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"features train classification data report\\n\")\n",
    "r1 = pd.DataFrame(classification_report(Segmentations_train,Segmentations_pred_train, output_dict=True))\n",
    "print(r1.to_markdown(tablefmt='grid', floatfmt='.2f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Score for Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5229244114002478"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Segmentations_test,Segmentations_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features test classification data report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features test classification data report\n",
      "\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n",
      "|           |      A |      B |      C |      D |   accuracy |   macro avg |   weighted avg |\n",
      "+===========+========+========+========+========+============+=============+================+\n",
      "| precision |   0.45 |   0.38 |   0.59 |   0.64 |       0.52 |        0.51 |           0.52 |\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n",
      "| recall    |   0.53 |   0.34 |   0.50 |   0.69 |       0.52 |        0.51 |           0.52 |\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n",
      "| f1-score  |   0.49 |   0.36 |   0.54 |   0.66 |       0.52 |        0.51 |           0.52 |\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n",
      "| support   | 594.00 | 544.00 | 607.00 | 676.00 |       0.52 |     2421.00 |        2421.00 |\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"features test classification data report\\n\")\n",
    "r1 = pd.DataFrame(classification_report(Segmentations_test,Segmentations_pred_test, output_dict=True))\n",
    "print(r1.to_markdown(tablefmt='grid', floatfmt='.2f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Random Forest Classification model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomForestClassifier = RandomForestClassifier(random_state=5,max_depth=7,n_estimators=9)\n",
    "randomForestClassifier.fit(Features_train, Segmentations_train)\n",
    "importance = randomForestClassifier.feature_importances_\n",
    "max=-1\n",
    "maxIndex=-1\n",
    "for i,v in enumerate(importance):\n",
    "    if(max<v):\n",
    "        max=v\n",
    "        maxIndex=i\n",
    "print(maxIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Decision Tree Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Segmentations_pred_train = randomForestClassifier.predict(Features_train)\n",
    "Segmentations_pred_test = randomForestClassifier.predict(Features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Segmentations_test, Segmentations_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Score for Random Forest Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5705684434212857"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Segmentations_train,Segmentations_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features train classification data report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features train classification data report\n",
      "\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n",
      "|           |       A |       B |       C |       D |   accuracy |   macro avg |   weighted avg |\n",
      "+===========+=========+=========+=========+=========+============+=============+================+\n",
      "| precision |    0.49 |    0.48 |    0.59 |    0.68 |       0.57 |        0.56 |           0.57 |\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n",
      "| recall    |    0.53 |    0.43 |    0.55 |    0.74 |       0.57 |        0.56 |           0.57 |\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n",
      "| f1-score  |    0.51 |    0.46 |    0.57 |    0.71 |       0.57 |        0.56 |           0.57 |\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n",
      "| support   | 1378.00 | 1314.00 | 1363.00 | 1592.00 |       0.57 |     5647.00 |        5647.00 |\n",
      "+-----------+---------+---------+---------+---------+------------+-------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"features train classification data report\\n\")\n",
    "r1 = pd.DataFrame(classification_report(Segmentations_train,Segmentations_pred_train, output_dict=True))\n",
    "print(r1.to_markdown(tablefmt='grid', floatfmt='.2f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Score for Random Forest Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5245766212308963"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Segmentations_test,Segmentations_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features test calssification data report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features test classification data report\n",
      "\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n",
      "|           |      A |      B |      C |      D |   accuracy |   macro avg |   weighted avg |\n",
      "+===========+========+========+========+========+============+=============+================+\n",
      "| precision |   0.45 |   0.40 |   0.58 |   0.63 |       0.52 |        0.51 |           0.52 |\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n",
      "| recall    |   0.48 |   0.35 |   0.55 |   0.69 |       0.52 |        0.52 |           0.52 |\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n",
      "| f1-score  |   0.46 |   0.37 |   0.56 |   0.66 |       0.52 |        0.51 |           0.52 |\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n",
      "| support   | 594.00 | 544.00 | 607.00 | 676.00 |       0.52 |     2421.00 |        2421.00 |\n",
      "+-----------+--------+--------+--------+--------+------------+-------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"features test classification data report\\n\")\n",
    "r1 = pd.DataFrame(classification_report(Segmentations_test,Segmentations_pred_test, output_dict=True))\n",
    "print(r1.to_markdown(tablefmt='grid', floatfmt='.2f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the new customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('new_customers.csv')\n",
    "newFeatures = dataset.iloc[:, :].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan for string variables\n",
    "nan_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "newFeatures[:, 0:2] = nan_imputer.fit_transform(newFeatures[:, 0:2])\n",
    "newFeatures[:, 3:5] = nan_imputer.fit_transform(newFeatures[:, 3:5])\n",
    "newFeatures[:, 6:7] = nan_imputer.fit_transform(newFeatures[:, 6:7])\n",
    "\n",
    "# nan for a numerical variables\n",
    "nan_num_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "newFeatures[:, 2:3] = nan_num_imputer.fit_transform(newFeatures[:, 2:3])\n",
    "newFeatures[:, 5:6] = nan_num_imputer.fit_transform(newFeatures[:, 5:6])\n",
    "newFeatures[:, 7:8] = nan_num_imputer.fit_transform(newFeatures[:, 7:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable (Gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "newFeatures[:,0]= labelEncoder.fit_transform(newFeatures[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable (Ever_Married)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "newFeatures[:,1]= labelEncoder.fit_transform(newFeatures[:,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable (Graduated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "newFeatures[:,3]= labelEncoder.fit_transform(newFeatures[:,3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable(Spending_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for observation in newFeatures:\n",
    "    observation[6] = Spending_Score_Map[observation[6]]\n",
    "labelEncoder = LabelEncoder()\n",
    "newFeatures[:,6]= labelEncoder.fit_transform(newFeatures[:,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Independent Variable (Profession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnTransformer = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [4])], remainder='passthrough')\n",
    "newFeatures = np.array(columnTransformer.fit_transform(newFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature Scaling</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "newFeatures[:, 11:12] = sc.fit_transform(newFeatures[:, 11:12])\n",
    "newFeatures[:, 14:15] = sc.fit_transform(newFeatures[:, 14:15])\n",
    "newFeatures[:, 15:16] = sc.fit_transform(newFeatures[:, 15:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the newCustomer set results Using Decision Tree Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 0, 'C': 0, 'D': 0}\n"
     ]
    }
   ],
   "source": [
    "newSegmentations_pred = decisionTreeClassifier.predict(newFeatures)\n",
    "\n",
    "data_distributed = {'A':0,'B':0,'C':0,'D':0} \n",
    "for i in newSegmentations_pred: \n",
    "    if(i==0): \n",
    "        data_distributed['A'] +=1 \n",
    "    if(i==1): \n",
    "        data_distributed['B'] +=1  \n",
    "    if(i==2): \n",
    "        data_distributed['C'] +=1  \n",
    "    if(i==3): \n",
    "        data_distributed['D'] +=1  \n",
    "print(data_distributed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the newCustomer set results Using Random Forest classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 0, 'C': 0, 'D': 0}\n"
     ]
    }
   ],
   "source": [
    "newSegmentations_pred = randomForestClassifier.predict(newFeatures)\n",
    "data_distributed = {'A':0,'B':0,'C':0,'D':0} \n",
    "for i in newSegmentations_pred: \n",
    "    if(i==0): \n",
    "        data_distributed['A'] +=1 \n",
    "    if(i==1): \n",
    "        data_distributed['B'] +=1  \n",
    "    if(i==2): \n",
    "        data_distributed['C'] +=1  \n",
    "    if(i==3): \n",
    "        data_distributed['D'] +=1  \n",
    "print(data_distributed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b6079af21e979945c8c029267b6c1970daa06c7ff8dc867c0071b7e9ea55e6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
